{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data - How Institutions of Higher Education Can Mine The Key Ingredient of  A Successful Analytics Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of data analytics programs that foster robust decision support systems have become a key component of strategic initiatives for institutions of higher-education. However, college and university leadership teams remain unsure of how to effectively incorporate analytics into the institution's operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object of this project is to explore the power of a predictive system based on the notion that at the end of each semester we can diagnose the chances of a student graduating in 4 years based on all available information up to that point. \n",
    "\n",
    "One main objective is to identify an information saturation point upon which actionable intervention is implemented. The hypothesis is that there exists a local maxima saturation point which provides the most appropriate intervention point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "\n",
    "# Database\n",
    "import cx_Oracle\n",
    "from sqlalchemy import create_engine\n",
    "from getpass import getpass\n",
    "\n",
    "# Tools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import string\n",
    "from builtins import range\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "#import pandas_profiling\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Analytics\n",
    "#import pymc3 as pm\n",
    "from scipy.stats import beta\n",
    "\n",
    "#IMBALANCED DATA\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "\n",
    "#SciKitLearn Models\n",
    "# from sklearn.linear_model import LogisticRegression, ElasticNetCV, SGDClassifier\n",
    "# from sklearn import svm\n",
    "# from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier, AdaBoostClassifier,VotingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neural_network import MLPClassifier #(wait for scikit release 18.0)\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import LassoCV\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#XgBoost Model ###################################################################################\n",
    "# import os\n",
    "# mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "# os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "import xgboost as xgb\n",
    "##################################################################################################\n",
    "\n",
    "#MODEL SELECTION, #EVALUATION METRICS\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Data: Performance & Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grades Data\n",
    "First we obtain the students grades along with a few variables. The goal is to aggregate the grade records to a semester summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: jbraswell\n",
      "Enter password: ········\n"
     ]
    }
   ],
   "source": [
    "username = input('Enter username: ')\n",
    "\n",
    "password = getpass(prompt='Enter password: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = 'iraarchd'\n",
    "host = 'ira-oradb01d.its.csulb.edu'\n",
    "port = '1521'\n",
    "grades_query = 'grd_msk.sql'\n",
    "dem_query = 'dae_msk.sql'\n",
    "\n",
    "def db_query(username, password, service_name, host, port, query):\n",
    "\n",
    "    dsn = cx_Oracle.makedsn(host, port, service_name=service_name)\n",
    "\n",
    "    cstr = 'oracle://{user}:{password}@{dsn}'.format(\n",
    "        user=username,\n",
    "        password=password,\n",
    "        dsn=dsn\n",
    "    )\n",
    "\n",
    "    engine =  create_engine(\n",
    "        cstr,\n",
    "        convert_unicode=False,\n",
    "        pool_recycle=10,\n",
    "        pool_size=50,\n",
    "    )\n",
    "\n",
    "    with open(query, 'r') as f:\n",
    "        data=f.read()#.replace('\\n', '')\n",
    "        \n",
    "    return (data, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\base.py:1316: SAWarning: Oracle compatibility version (18, 5, 0, 0, 0) is known to have a maximum identifier length of 128, rather than the historical default of 30. SQLAlchemy 1.4 will use 128 for this database; please set max_identifier_length=128 in create_engine() in order to test the application with this new length, or set to 30 in order to assure that 30 continues to be used.  In particular, pay close attention to the behavior of database migrations as dynamically generated names may change. See the section 'Max Identifier Lengths' in the SQLAlchemy Oracle dialect documentation for background.\n",
      "  % ((self.server_version_info,))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\base.py:1273: SAWarning: Could not determine compatibility version: (cx_Oracle.DatabaseError) ORA-00942: table or view does not exist\n",
      "[SQL: SELECT value FROM v$parameter WHERE name = 'compatible']\n",
      "(Background on this error at: http://sqlalche.me/e/4xp6)\n",
      "  util.warn(\"Could not determine compatibility version: %s\" % err)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709796, 37)\n",
      "(12251, 23)\n"
     ]
    }
   ],
   "source": [
    "grades, engine = db_query(username, password, service_name, host, port, grades_query)\n",
    "grd = pd.read_sql(grades, engine)\n",
    "\n",
    "demo, engine = db_query(username, password, service_name, host, port, dem_query)\n",
    "dem = pd.read_sql(demo, engine)\n",
    "\n",
    "\n",
    "print(grd.shape)\n",
    "print(dem.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem[dem['emplid'] == '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd[grd['emplid'] == '3'].sort_values(by=['term_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encodes\n",
    "\n",
    "Get Dummies Documentation\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all our column names in upper case for ease of reference\n",
    "\n",
    "grd.columns = map(str.upper, grd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709796, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = pd.concat([grd,pd.get_dummies(grd['OFFICIAL_GRADE'], drop_first=True)], axis=1)\n",
    "\n",
    "grd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 'UNKNOWN' to more unique string to avoid having columns with same name after one-hot-encode\n",
    "\n",
    "dem['first_generation'] = dem['first_generation'].apply(lambda x: 'First Generation Unknown' if x == 'UNKNOWN' else x)\n",
    "dem['ethnicity'] = dem['ethnicity'].apply(lambda x: 'ETHNICITY UNKNOWN' if x == 'UNKNOWN' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EMPLID', 'DEM_COHORT', 'DEM_DIFF_INDX', 'DAE_EMPLID', 'GENDER',\n",
       "       'ETHNICITY', 'FIRST_GENERATION', 'DEP_FAMILY_SIZE', 'MINORITY',\n",
       "       'APPLICANT_FAMILY_SIZE', 'APPLICANT_INCOME', 'PELL_TOT_EMPLID',\n",
       "       'PELL_ELIGIBILITY', 'ESA_EMPLID', 'ACT_COMP', 'ACT_READ', 'ACT_MATH',\n",
       "       'ACT_ENG', 'ACT_SCI', 'SAT_READ', 'SAT_MATH', 'SAT_COMP', 'GPA_HS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all our column names in upper case for ease of reference\n",
    "\n",
    "dem.columns = map(str.upper, dem.columns)\n",
    "dem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = pd.concat([dem,\n",
    "                pd.get_dummies(dem['GENDER'], drop_first=True, prefix='GENDR'),\n",
    "                pd.get_dummies(dem['ETHNICITY'], drop_first=False),\n",
    "                pd.get_dummies(dem['FIRST_GENERATION'], drop_first=False),\n",
    "                pd.get_dummies(dem['DEP_FAMILY_SIZE'], drop_first=False, prefix='DEP_FAM'),\n",
    "                pd.get_dummies(dem['MINORITY'], drop_first=False, prefix='URM'), \n",
    "                pd.get_dummies(dem['APPLICANT_FAMILY_SIZE'], drop_first=False, prefix='APP_FAM'),\n",
    "                pd.get_dummies(dem['APPLICANT_INCOME'], drop_first=False, prefix='INCM'),\n",
    "                pd.get_dummies(dem['PELL_ELIGIBILITY'], drop_first=False, prefix='PELL')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EMPLID', 'DEM_COHORT', 'DEM_DIFF_INDX', 'DAE_EMPLID', 'GENDER',\n",
       "       'ETHNICITY', 'FIRST_GENERATION', 'DEP_FAMILY_SIZE', 'MINORITY',\n",
       "       'APPLICANT_FAMILY_SIZE', 'APPLICANT_INCOME', 'PELL_TOT_EMPLID',\n",
       "       'PELL_ELIGIBILITY', 'ESA_EMPLID', 'ACT_COMP', 'ACT_READ', 'ACT_MATH',\n",
       "       'ACT_ENG', 'ACT_SCI', 'SAT_READ', 'SAT_MATH', 'SAT_COMP', 'GPA_HS',\n",
       "       'GENDR_M', 'AFRICAN AMERICAN', 'ASIAN AMERICAN', 'CAUCASIAN',\n",
       "       'ETHNICITY UNKNOWN', 'LATINO/LATINA', 'NATIVE AMERICAN',\n",
       "       'PACIFIC ISLANDER', 'TWO OR MORE RACES, INCLUDING MINORITY',\n",
       "       'TWO OR MORE RACES, NON-MINORITIES', 'VISA NON U.S.',\n",
       "       'CONTINUING GENERATION STUDENT', 'FIRST GENERATION STUDENT',\n",
       "       'FIRST GENERATION UNKNOWN', 'DEP_FAM_1', 'DEP_FAM_10', 'DEP_FAM_11',\n",
       "       'DEP_FAM_12', 'DEP_FAM_13', 'DEP_FAM_14', 'DEP_FAM_15', 'DEP_FAM_2',\n",
       "       'DEP_FAM_25', 'DEP_FAM_3', 'DEP_FAM_4', 'DEP_FAM_5', 'DEP_FAM_6',\n",
       "       'DEP_FAM_7', 'DEP_FAM_8', 'DEP_FAM_9', 'DEP_FAM_NA', 'URM_MINORITY',\n",
       "       'URM_NON-MINORITY', 'URM_UNKNOWN', 'URM_VISA NON U.S.', 'APP_FAM_1',\n",
       "       'APP_FAM_2', 'APP_FAM_3', 'APP_FAM_4', 'APP_FAM_5', 'APP_FAM_6',\n",
       "       'APP_FAM_7', 'APP_FAM_8', 'APP_FAM_9', 'APP_FAM_NA',\n",
       "       'INCM_$12,000 TO $23,999', 'INCM_$24,000 TO $35,999',\n",
       "       'INCM_$36,000 TO $47,999', 'INCM_$6,000 TO $11,999',\n",
       "       'INCM_$60,000 OR MORE', 'INCM_CANNOT ESTIMATE', 'INCM_LESS THEN $6000',\n",
       "       'INCM_NO RESPONSE', 'PELL_NON TRADITIONAL', 'PELL_TRADITIONAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem.columns = map(str.upper, dem.columns)\n",
    "dem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.drop(labels=['GENDER', 'ETHNICITY', 'FIRST_GENERATION',\n",
    "       'DEP_FAMILY_SIZE', 'MINORITY', 'APPLICANT_FAMILY_SIZE',\n",
    "       'APPLICANT_INCOME', 'PELL_ELIGIBILITY'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Features and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Degree Difference calculation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem['DEM_N'] = dem['DEM_DIFF_INDX'].apply(lambda x: x if (x >= 0) == False \n",
    "                             else int(x/5+1) if (x%10 == 0 or x%10 == 7) \n",
    "                             else int((x + 2)/5) )\n",
    "\n",
    "dem['YRS_TO_GRAD'] = dem['DEM_N'] * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem[['DEM_DIFF_INDX','YRS_TO_GRAD']].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = pd.concat([dem,pd.get_dummies(dem['YRS_TO_GRAD'], drop_first=False, prefix='GRAD_IN')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DEM_N' 'PELLTOT_EMPLID' 'YRS_TO_GRAD'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5132d9e448a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m dem.drop(labels=['DEM_DIFF_INDX','DEM_N','DAE_EMPLID','PELLTOT_EMPLID','ESA_EMPLID',\n\u001b[1;32m----> 2\u001b[1;33m                  'YRS_TO_GRAD'], axis=1, inplace=True)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DEM_N' 'PELLTOT_EMPLID' 'YRS_TO_GRAD'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dem.drop(labels=['DEM_DIFF_INDX','DEM_N','DAE_EMPLID','PELLTOT_EMPLID','ESA_EMPLID',\n",
    "                 'YRS_TO_GRAD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Change Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Variables to Calculate GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd['OFFICIAL_GRADE'].apply(lambda x: None if x in ['AU','CR','NC','RD','RP','W','WE'] else 1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These statements keep only those grade points, and units taken that counted towards GPA.  \n",
    "#Notice what the lambda function above returned.\n",
    "\n",
    "grd['GRADE_POINTS_IN_GPA'] = grd['GRADE_POINTS'] * grd['OFFICIAL_GRADE'].apply(\n",
    "    lambda x: None if x in ['AU','CR','NC','RD','RP','W','WE'] else 1\n",
    ")\n",
    "\n",
    "grd['UNITS_IN_GPA'] = grd['UNITS_TAKEN'] * grd['OFFICIAL_GRADE'].apply(\n",
    "    lambda x: None if x in ['AU','CR','NC','RD','RP','W','WE'] else 1\n",
    ")\n",
    "\n",
    "grd['UNITS_FOR_CREDIT'] = grd['UNITS_TAKEN'] * grd['OFFICIAL_GRADE'].apply(\n",
    "    lambda x: None if x in ['AU','NC','RD','RP','W','WE'] else 1\n",
    ")\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "#BCMP was a measure created in pre-processing that takes the grade points earned in \n",
    "#Biology, Chemistry,Math and Physics classes.  We expect these courses to have a strong relationship to timely graduation.\n",
    "\n",
    "grd['BCMP_GRADE_POINTS_IN_GPA'] = grd['BCMP'] * grd['GRADE_POINTS'] * grd['OFFICIAL_GRADE'].apply(\n",
    "    lambda x: None if x in ['AU','CR','NC','RD','RP','W','WE'] else 1\n",
    ")\n",
    "\n",
    "grd['BCMP_UNITS_IN_GPA'] = grd['BCMP_UNITS_TAKEN'] * grd['OFFICIAL_GRADE'].apply(\n",
    "    lambda x: None if x in ['AU','CR','NC','RD','RP','W','WE'] else 1\n",
    ")\n",
    "\n",
    "grd['BCMP_UNITS_FOR_CREDIT'] = grd['BCMP'] * grd['UNITS_TAKEN'] * grd['OFFICIAL_GRADE'].apply(\n",
    "    lambda x: None if x in ['AU','NC','RD','RP','W','WE'] else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a feature that measures how many credits were taken during Winter and Summer terms.\n",
    "grd['SUMMER'] = (grd['TERM_CODE'].apply(lambda x: str(x)[-1]) == '3')* 1 * grd['UNITS_FOR_CREDIT']\n",
    "\n",
    "grd['WINTER'] = (grd['TERM_CODE'].apply(lambda x: str(x)[-1]) == '1')* 1 * grd['UNITS_FOR_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Cleanup\n",
    "grd = grd.sort_values(by=['EMPLID','TERM_CODE']).copy()[['COHORT', \n",
    "                 'EMPLID', \n",
    "                 'TERM_CODE',\n",
    "                 'EOT_ACAD_PLAN_CD',\n",
    "                 'GRADE_POINTS_IN_GPA',\n",
    "                 'UNITS_TAKEN',\n",
    "                 'UNITS_IN_GPA',\n",
    "                 'UNITS_FOR_CREDIT',\n",
    "                 'BCMP',\n",
    "                 'BCMP_GRADE_POINTS_IN_GPA',\n",
    "                 'BCMP_UNITS_TAKEN',\n",
    "                 'BCMP_UNITS_IN_GPA',\n",
    "                 'BCMP_UNITS_FOR_CREDIT',\n",
    "                 'A', \n",
    "                 'AU', \n",
    "                 'B',\n",
    "                 'C', \n",
    "                 'CR', \n",
    "                 'D', \n",
    "                 'F', \n",
    "                 'I', \n",
    "                 'NC', \n",
    "                 'RP', \n",
    "                 'W', \n",
    "                 'WE', \n",
    "                 'WU',\n",
    "                 'SUMMER',\n",
    "                 'WINTER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate and Reduce from Course Dimension to Term Dimension:  We want our data to be in the format of a single row for each term, rather than having a single row for each course in a term.  In other words, we are reducing our dataset from a course dimension to a term dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = { 'GRADE_POINTS_IN_GPA':'sum',\n",
    "                 'UNITS_TAKEN':'sum',\n",
    "                 'UNITS_IN_GPA':'sum',\n",
    "                 'UNITS_FOR_CREDIT':'sum',\n",
    "                 'BCMP':'sum',\n",
    "                 'BCMP_GRADE_POINTS_IN_GPA':'sum',\n",
    "                 'BCMP_UNITS_TAKEN':'sum',\n",
    "                 'BCMP_UNITS_IN_GPA':'sum',\n",
    "                 'BCMP_UNITS_FOR_CREDIT':'sum',\n",
    "                 'A':'sum', \n",
    "                 'AU':'sum', \n",
    "                 'B':'sum',\n",
    "                 'C':'sum', \n",
    "                 'CR':'sum', \n",
    "                 'D':'sum', \n",
    "                 'F':'sum', \n",
    "                 'I':'sum', \n",
    "                 'NC':'sum', \n",
    "                 'RP':'sum', \n",
    "                 'W':'sum', \n",
    "                 'WE':'sum', \n",
    "                 'WU':'sum',\n",
    "               'SUMMER':'sum',\n",
    "               'WINTER':'sum'}\n",
    "\n",
    "grouped_agg = grd.groupby(['COHORT','EMPLID','TERM_CODE','EOT_ACAD_PLAN_CD']).agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_agg[grouped_agg['EMPLID'] == '3'].sort_values(by=['TERM_CODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cummulative Sums of Grade Points and GPA Units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cumsum = grd[['EMPLID',\n",
    "                             'TERM_CODE',\n",
    "                             'EOT_ACAD_PLAN_CD',\n",
    "                             'COHORT',\n",
    "                             'GRADE_POINTS_IN_GPA',\n",
    "                             'UNITS_TAKEN',\n",
    "                             'UNITS_IN_GPA',\n",
    "                             'UNITS_FOR_CREDIT',\n",
    "                             'BCMP',\n",
    "                             'BCMP_GRADE_POINTS_IN_GPA',\n",
    "                             'BCMP_UNITS_TAKEN',\n",
    "                             'BCMP_UNITS_IN_GPA',\n",
    "                             'BCMP_UNITS_FOR_CREDIT',\n",
    "                             'SUMMER',\n",
    "                             'WINTER']].groupby(['EMPLID',\n",
    "                                                 'TERM_CODE',\n",
    "                                                 'COHORT',\n",
    "                                                 'EOT_ACAD_PLAN_CD',]).sum().groupby(level=[0]).cumsum().reset_index()\n",
    "\n",
    "grouped_cumsum = grouped_cumsum.add_prefix('CUM_')\n",
    "\n",
    "grd = pd.concat([grouped_agg,grouped_cumsum],axis=1)\n",
    "\n",
    "grd.drop(['CUM_EMPLID','CUM_TERM_CODE','CUM_COHORT','CUM_EOT_ACAD_PLAN_CD'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Term and Cummulative GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd['TERM_GPA'] = grd['GRADE_POINTS_IN_GPA'] / grd['UNITS_IN_GPA']\n",
    "\n",
    "grd['CUM_GPA'] = grd['CUM_GRADE_POINTS_IN_GPA'] / grd['CUM_UNITS_IN_GPA']\n",
    "\n",
    "grd['BCMP_TERM_GPA'] = grd['BCMP_GRADE_POINTS_IN_GPA'] / grd['BCMP_UNITS_IN_GPA']\n",
    "\n",
    "grd['BCMP_CUM_GPA'] = grd['CUM_BCMP_GRADE_POINTS_IN_GPA'] / grd['CUM_BCMP_UNITS_IN_GPA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for NaN values since division by 0 is possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COHORT                              0\n",
       "EMPLID                              0\n",
       "TERM_CODE                           0\n",
       "EOT_ACAD_PLAN_CD                    0\n",
       "GRADE_POINTS_IN_GPA                 0\n",
       "UNITS_TAKEN                         0\n",
       "UNITS_IN_GPA                        0\n",
       "UNITS_FOR_CREDIT                    0\n",
       "BCMP                                0\n",
       "BCMP_GRADE_POINTS_IN_GPA            0\n",
       "BCMP_UNITS_TAKEN                    0\n",
       "BCMP_UNITS_IN_GPA                   0\n",
       "BCMP_UNITS_FOR_CREDIT               0\n",
       "A                                   0\n",
       "AU                                  0\n",
       "B                                   0\n",
       "C                                   0\n",
       "CR                                  0\n",
       "D                                   0\n",
       "F                                   0\n",
       "I                                   0\n",
       "NC                                  0\n",
       "RP                                  0\n",
       "W                                   0\n",
       "WE                                  0\n",
       "WU                                  0\n",
       "SUMMER                              0\n",
       "WINTER                              0\n",
       "CUM_GRADE_POINTS_IN_GPA             0\n",
       "CUM_UNITS_TAKEN                     0\n",
       "CUM_UNITS_IN_GPA                    0\n",
       "CUM_UNITS_FOR_CREDIT                0\n",
       "CUM_BCMP                            0\n",
       "CUM_BCMP_GRADE_POINTS_IN_GPA        0\n",
       "CUM_BCMP_UNITS_TAKEN                0\n",
       "CUM_BCMP_UNITS_IN_GPA               0\n",
       "CUM_BCMP_UNITS_FOR_CREDIT           0\n",
       "CUM_SUMMER                          0\n",
       "CUM_WINTER                          0\n",
       "TERM_GPA                         1915\n",
       "CUM_GPA                            96\n",
       "BCMP_TERM_GPA                   91473\n",
       "BCMP_CUM_GPA                    12247\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute missing Term and Cum GPA\n",
    "\n",
    "In this instance it is reasonable to set the Term GPA and CumGPA to zero since NaNs result from Units in GPA and Cum Units in GPA being zero. This means either the student had no Units in GPA for a given term or the Cum Units in GPA was zero since the student failed to pass units in the initial term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Load Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firt we need to find a convenient way to calculate the number of terms that have passed since the student arrived\n",
    "\n",
    "Start with difference in terms.\n",
    "\n",
    "$The \\ \\ pattern \\ \\  of \\ \\ the \\ \\ difference \\ \\  d \\ \\ 0,7,8,9,10,17,18,19,20,... \\ \\ $\n",
    "\n",
    "$Pattern \\ \\ when \\ \\ d \\ \\ mod \\ \\ 10 \\ \\ is \\ \\ 0$    $$N = 2\\dfrac{d}{10} + 1 = \\dfrac{d}{5} + 1$$\n",
    "\n",
    "Pattern when d mod 10 is 8    $$N = 2\\left(\\dfrac{d - 8}{10} + 1\\right) = \\dfrac{d + 2}{5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the term difference 'd'\n",
    "grd['TERM_DIFF'] = pd.to_numeric(grd['TERM_CODE']) - pd.to_numeric(grd['COHORT'])\n",
    "\n",
    "\n",
    "# SEMESTER INDICATOR #\n",
    "grd['N'] = grd['TERM_DIFF'].apply(lambda x: int(x/5+1) if x%10 == 0 else int((x + 2)/5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Load Index\n",
    "\n",
    "$L_s = \\dfrac{\\sum_{i=1}^{k_s} u_i}{U_s}$\n",
    "\n",
    "$u_i: units\\ \\ earned \\ \\ by \\ \\ taking \\ \\ class \\ \\ i.$\n",
    "\n",
    "$k_s: number \\ \\ of \\ \\ classes \\ \\ taken \\ \\ in \\ \\ semester \\ \\ s.$\n",
    "\n",
    "$U_s: number \\ \\ of \\ \\ units \\ \\ prescribed \\ \\ to \\ \\ be \\ \\ earned \\ \\ by \\ \\ semester \\ \\ s.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many units would a person needed to have taken at term n in order to be on track for 4 year graduation.\n",
    "grd['PRESCRIBED_UNITS'] = grd['N'] * 15\n",
    "\n",
    "grd['LOAD_INDEX'] = grd['CUM_UNITS_FOR_CREDIT'] / grd['PRESCRIBED_UNITS']\n",
    "\n",
    "grd['COMPLETION_RATE'] = grd['UNITS_FOR_CREDIT'] / grd['UNITS_TAKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPLID</th>\n",
       "      <th>TERM_CODE</th>\n",
       "      <th>N</th>\n",
       "      <th>PRESCRIBED_UNITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47716</th>\n",
       "      <td>3</td>\n",
       "      <td>2104</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47717</th>\n",
       "      <td>3</td>\n",
       "      <td>2112</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47718</th>\n",
       "      <td>3</td>\n",
       "      <td>2124</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47719</th>\n",
       "      <td>3</td>\n",
       "      <td>2132</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47720</th>\n",
       "      <td>3</td>\n",
       "      <td>2134</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47721</th>\n",
       "      <td>3</td>\n",
       "      <td>2142</td>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47722</th>\n",
       "      <td>3</td>\n",
       "      <td>2144</td>\n",
       "      <td>9</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47723</th>\n",
       "      <td>3</td>\n",
       "      <td>2152</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47724</th>\n",
       "      <td>3</td>\n",
       "      <td>2154</td>\n",
       "      <td>11</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMPLID TERM_CODE   N  PRESCRIBED_UNITS\n",
       "47716      3      2104   1                15\n",
       "47717      3      2112   2                30\n",
       "47718      3      2124   5                75\n",
       "47719      3      2132   6                90\n",
       "47720      3      2134   7               105\n",
       "47721      3      2142   8               120\n",
       "47722      3      2144   9               135\n",
       "47723      3      2152  10               150\n",
       "47724      3      2154  11               165"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd[grd['EMPLID'] == '3'][['EMPLID','TERM_CODE','N','PRESCRIBED_UNITS']].head(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Exclusive Load Index \n",
    "\n",
    "We are counting up the Units taken for credit only after the student arrived on campus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd['UNITS_FOR_CREDIT_EXCLUDE'] = (grd['TERM_DIFF'] >= 0) * grd['UNITS_FOR_CREDIT']\n",
    "\n",
    "grouped_cumsum = grd[['EMPLID',\n",
    "                      'TERM_CODE',\n",
    "                      'COHORT',\n",
    "                      'UNITS_FOR_CREDIT_EXCLUDE']].groupby(['EMPLID',\n",
    "                                                                 'TERM_CODE',\n",
    "                                                                 'COHORT']).sum().groupby(level=[0]).cumsum().reset_index()\n",
    "\n",
    "grouped_cumsum = grouped_cumsum.add_prefix('CUM_')\n",
    "\n",
    "grd = pd.concat([grd,grouped_cumsum],axis=1)\n",
    "\n",
    "grd['N_EXCLUDE'] = grd['TERM_DIFF'].apply(lambda x: 0 if x < 0 else(int(x/5+1) if int(repr(x)[-1]) == 0 else int((x + 2)/5) ))\n",
    "\n",
    "grd['PRESCRIBED_UNITS_EXCLUDE'] = grd['N_EXCLUDE'] * 15\n",
    "\n",
    "grd['LOAD_INDEX_EXCLUDE'] = grd['CUM_UNITS_FOR_CREDIT_EXCLUDE'] / grd['PRESCRIBED_UNITS_EXCLUDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Only Prior Load Index Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd['LOAD_INDEX_ONLY']=grd['LOAD_INDEX']-grd['LOAD_INDEX_EXCLUDE']\n",
    "\n",
    "grouped_diff = grd[['EMPLID', 'LOAD_INDEX_ONLY']].groupby(['EMPLID']).transform(max).reset_index()\n",
    "\n",
    "grd = grd.drop(columns='LOAD_INDEX_ONLY')\n",
    "\n",
    "grd = pd.concat([grd,grouped_diff],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd[['LOAD_INDEX_ONLY','N']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DFW Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd['DFW'] = grd['D'] + grd['F'] + grd['I'] + grd['NC'] + grd['W'] + grd['WE'] + grd['WU']\n",
    "\n",
    "grd['DFW_RATE'] = grd['DFW']/grd['UNITS_TAKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cleanup\n",
    "\n",
    "We have used these to calculate various metrics, and no longer need them for our analasys.  They can be dropped to clean up our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.drop(labels=['GRADE_POINTS_IN_GPA','UNITS_IN_GPA','BCMP_GRADE_POINTS_IN_GPA',\n",
    "                'BCMP_UNITS_IN_GPA','CUM_GRADE_POINTS_IN_GPA', \n",
    "                'CUM_UNITS_IN_GPA', 'CUM_BCMP_GRADE_POINTS_IN_GPA', 'TERM_DIFF', \n",
    "                 'CUM_EMPLID', 'CUM_TERM_CODE', 'CUM_COHORT',\n",
    "                 'CUM_UNITS_FOR_CREDIT_EXCLUDE', 'N_EXCLUDE', 'PRESCRIBED_UNITS_EXCLUDE', 'index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclude Rows Before $T_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = grd[grd['COHORT'] <= grd['TERM_CODE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Demographic and Academic Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = dem.rename(columns={'DEM_COHORT':'COHORT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is directly analagous to a SQL merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme = pd.merge(dem, grd, on=['EMPLID','COHORT'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(supreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(supreme).get_rejected_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme.drop(labels=[ 'DFW',\n",
    "#                       'AP',\n",
    "                      'BCMP_UNITS_FOR_CREDIT',\n",
    "                      'BCMP_UNITS_TAKEN',\n",
    "                      'CUM_BCMP_UNITS_FOR_CREDIT',\n",
    "                      'CUM_BCMP_UNITS_IN_GPA',\n",
    "                      'CUM_BCMP_UNITS_TAKEN',\n",
    "                      'CUM_UNITS_FOR_CREDIT',\n",
    "                      'INCM_NO RESPONSE',\n",
    "                      'UNITS_FOR_CREDIT',\n",
    "                      'URM_UNKNOWN',\n",
    "                      'URM_VISA NON U.S.'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_seq_items = supreme.columns.shape[0]\n",
    "\n",
    "supreme.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before doing anything it is good practice to split our datasets into Training and Testing sets.  We do this before any of our data wrangling to avoid any possible data 'leakage' between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 15497 students\n"
     ]
    }
   ],
   "source": [
    "students = pd.DataFrame(grd['EMPLID'].unique(), columns=['EMPLID'])\n",
    "\n",
    "print('there are {} students'.format(students.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the Trainning and Validation Student Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_train, students_dev = train_test_split(students, test_size=0.10, random_state=42)\n",
    "\n",
    "students_train = pd.DataFrame(students_train)\n",
    "\n",
    "students_dev = pd.DataFrame(students_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_train.columns = ['EMPLID']\n",
    "students_dev.columns = ['EMPLID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103946, 102)\n",
      "(11416, 102)\n"
     ]
    }
   ],
   "source": [
    "supreme_train = pd.merge(students_train, supreme, on='EMPLID', how='inner')\n",
    "print(supreme_train.shape)\n",
    "\n",
    "supreme_dev = pd.merge(students_dev, supreme, on='EMPLID', how='inner')\n",
    "print(supreme_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACT, SAT and HS GPA Scores Preprocessing - Simple Imputation\n",
    "\n",
    "Students may have ACT or SAT or both scores. The idea is to create a feature that would capture test performance in a general sense. The approach use here is to create three features that capture performance in Math, Reading and Composite performance. To this end we scale and center both ACT and SAT test scores in math, reading and composite and, in the event a student has taken both,choose the maximum normalized score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', 'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "       'SAT_MATH', 'SAT_COMP', 'GPA_HS']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['N'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scale the scores and choose the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', \n",
    "         'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "         'SAT_MATH', 'SAT_COMP']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', \n",
    "         'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "         'SAT_MATH', 'SAT_COMP']].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', \n",
    "         'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "         'SAT_MATH', 'SAT_COMP']] = preprocessing.scale(supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', \n",
    "                                                                         'ACT_ENG', 'ACT_SCI', 'SAT_READ', \n",
    "                                                                         'SAT_MATH', 'SAT_COMP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev[['ACT_COMP', 'ACT_READ', 'ACT_MATH', \n",
    "         'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "         'SAT_MATH', 'SAT_COMP']] = preprocessing.scale(supreme_dev[['ACT_COMP', 'ACT_READ', 'ACT_MATH', \n",
    "                                                                         'ACT_ENG', 'ACT_SCI', 'SAT_READ', \n",
    "                                                                         'SAT_MATH', 'SAT_COMP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', 'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "       'SAT_MATH', 'SAT_COMP']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['ACT_COMP', 'ACT_READ', 'ACT_MATH', 'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "       'SAT_MATH', 'SAT_COMP']].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['T_COMP'] = supreme_train[['ACT_COMP','SAT_COMP']].apply(lambda x: x.max(), axis=1)\n",
    "supreme_train['T_READ'] = supreme_train[['ACT_READ','SAT_READ']].apply(lambda x: x.max(), axis=1)\n",
    "supreme_train['T_MATH'] = supreme_train[['ACT_MATH','SAT_MATH']].apply(lambda x: x.max(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev['T_COMP'] = supreme_dev[['ACT_COMP','SAT_COMP']].apply(lambda x: x.max(), axis=1)\n",
    "supreme_dev['T_READ'] = supreme_dev[['ACT_READ','SAT_READ']].apply(lambda x: x.max(), axis=1)\n",
    "supreme_dev['T_MATH'] = supreme_dev[['ACT_MATH','SAT_MATH']].apply(lambda x: x.max(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['T_COMP','T_READ','T_MATH']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For now impute values by using the mean\n",
    "\n",
    "Note to team: I think this should come before we scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = supreme_train[['T_COMP','T_READ','T_MATH','GPA_HS']]\n",
    "\n",
    "imp_mean.fit(test_scores)  \n",
    "\n",
    "supreme_train[['T_COMP','T_READ','T_MATH','GPA_HS']] = imp_mean.transform(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = supreme_dev[['T_COMP','T_READ','T_MATH','GPA_HS']]\n",
    "\n",
    "imp_mean.fit(test_scores)  \n",
    "\n",
    "supreme_dev[['T_COMP','T_READ','T_MATH','GPA_HS']] = imp_mean.transform(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop unecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['N'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train.columns[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train.drop(['ACT_COMP', 'ACT_READ', 'ACT_MATH', 'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "       'SAT_MATH', 'SAT_COMP'], axis=1, inplace=True)\n",
    "\n",
    "supreme_dev.drop(['ACT_COMP', 'ACT_READ', 'ACT_MATH', 'ACT_ENG', 'ACT_SCI', 'SAT_READ',\n",
    "       'SAT_MATH', 'SAT_COMP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization using Quantile Transformation (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def norm_test(df):\n",
    "\n",
    "#             qt_normal_scaler = preprocessing.QuantileTransformer(output_distribution = 'normal', random_state=0)\n",
    "\n",
    "#             df_num = df[['CUM_GPA', 'BCMP_TERM_GPA', 'BCMP_CUM_GPA','DFW_RATE', 'T_COMP', 'T_READ', 'T_MATH', 'GPA_HS']]\n",
    "\n",
    "#             quantiletransformation_normal = qt_normal_scaler.fit_transform(df_num)\n",
    "#             quantiletransformation_normal_df = pd.DataFrame(quantiletransformation_normal ,columns=['CUM_GPA', 'BCMP_TERM_GPA', 'BCMP_CUM_GPA','DFW_RATE', 'T_COMP', 'T_READ', 'T_MATH', 'GPA_HS'])\n",
    "       \n",
    "            \n",
    "            \n",
    "#             df.loc[:,['CUM_GPA', 'BCMP_TERM_GPA', 'BCMP_CUM_GPA','DFW_RATE', 'T_COMP', 'T_READ', 'T_MATH', 'GPA_HS']] = quantiletransformation_normal_df.loc[:,['CUM_GPA', 'BCMP_TERM_GPA', 'BCMP_CUM_GPA','DFW_RATE', 'T_COMP', 'T_READ', 'T_MATH', 'GPA_HS']]\n",
    "        \n",
    "        \n",
    "            \n",
    "#             return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of Performance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', \n",
    "               'TERM_GPA', 'CUM_GPA','BCMP_TERM_GPA', \n",
    "               'BCMP_CUM_GPA']] = preprocessing.scale(supreme_train[['CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', \n",
    "                                                                     'TERM_GPA', 'CUM_GPA','BCMP_TERM_GPA', 'BCMP_CUM_GPA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev[['CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', \n",
    "               'TERM_GPA', 'CUM_GPA','BCMP_TERM_GPA', \n",
    "               'BCMP_CUM_GPA']] = preprocessing.scale(supreme_dev[['CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', \n",
    "                                                                     'TERM_GPA', 'CUM_GPA','BCMP_TERM_GPA', 'BCMP_CUM_GPA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \n",
    "    supreme_train[['CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', \n",
    "               'TERM_GPA', 'CUM_GPA','BCMP_TERM_GPA', \n",
    "               'BCMP_CUM_GPA']].mean()\n",
    ")\n",
    "\n",
    "print(\n",
    "    \n",
    "    supreme_train[['CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', \n",
    "               'TERM_GPA', 'CUM_GPA','BCMP_TERM_GPA', \n",
    "               'BCMP_CUM_GPA']].std()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The AP feature is null - impute with a constant for now\n",
    "\n",
    "Note to team:  I reccomend we drop AP from this presentation data entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['AP'] = 0\n",
    "\n",
    "supreme_dev['AP'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train.isnull().sum().head(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Major Plan Change Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Academic plans are 10 characters in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['EOT_ACAD_PLAN_CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['EOT_ACAD_PLAN_CD'] = supreme_train['EOT_ACAD_PLAN_CD'].apply(lambda x: str(x))\n",
    "supreme_dev['EOT_ACAD_PLAN_CD'] = supreme_dev['EOT_ACAD_PLAN_CD'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['EOT_ACAD_PLAN_CD'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The first 4 characters representthe department/subject. The 5th and 6th character encode the plan type and allows to separate pre-majors from majors. A change from pre-major to major in the same department/subject is not considered a major change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\n",
    "    supreme_train['EOT_ACAD_PLAN_CD'].apply(lambda x: x[4:6]).head()\n",
    ")\n",
    "\n",
    "print (\n",
    "    supreme_train['EOT_ACAD_PLAN_CD'].apply(lambda x: x[:4]).head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['SUBJECT'] = supreme_train['EOT_ACAD_PLAN_CD'].apply(lambda x: x[:4])\n",
    "supreme_train['PLAN_TYPE'] = supreme_train['EOT_ACAD_PLAN_CD'].apply(lambda x: x[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev['SUBJECT'] = supreme_dev['EOT_ACAD_PLAN_CD'].apply(lambda x: x[:4])\n",
    "supreme_dev['PLAN_TYPE'] = supreme_dev['EOT_ACAD_PLAN_CD'].apply(lambda x: x[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['EMPLID','SUBJECT','PLAN_TYPE']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Major Change indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['MAJOR_CHANGE_INDICATOR'] = ( supreme_train[['EMPLID','SUBJECT','PLAN_TYPE']] == supreme_train[['EMPLID','SUBJECT','PLAN_TYPE']].shift() ).apply(\n",
    "    \n",
    "    lambda x: 0 if x[0] == False \n",
    "           \n",
    "           or ( x[0] == True and x[1] == True and x[2] == True ) \n",
    "           \n",
    "           or ( x[0] == True and x[1] == True and x[2] == False )\n",
    "           \n",
    "           else 1 if ( x[0] == True and x[1] == False and x[2] == True )\n",
    "           \n",
    "           or ( x[0] == True and x[1] == False and x[2] == False )\n",
    "           \n",
    "           else None,\n",
    "           \n",
    "           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev['MAJOR_CHANGE_INDICATOR'] = ( supreme_dev[['EMPLID','SUBJECT','PLAN_TYPE']] == supreme_dev[['EMPLID','SUBJECT','PLAN_TYPE']].shift() ).apply(\n",
    "    \n",
    "    lambda x: 0 if x[0] == False \n",
    "           \n",
    "           or ( x[0] == True and x[1] == True and x[2] == True ) \n",
    "           \n",
    "           or ( x[0] == True and x[1] == True and x[2] == False )\n",
    "           \n",
    "           else 1 if ( x[0] == True and x[1] == False and x[2] == True )\n",
    "           \n",
    "           or ( x[0] == True and x[1] == False and x[2] == False )\n",
    "           \n",
    "           else None,\n",
    "           \n",
    "           axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Create a cumulative Major Change Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cumsum = supreme_train[['EMPLID',\n",
    "                             'TERM_CODE',\n",
    "                             'EOT_ACAD_PLAN_CD',\n",
    "                             'COHORT',\n",
    "                             'MAJOR_CHANGE_INDICATOR'\n",
    "                             ]].groupby(['EMPLID',\n",
    "                                                 'TERM_CODE',\n",
    "                                                 'EOT_ACAD_PLAN_CD',\n",
    "                                                 'COHORT',\n",
    "                                                 ]).sum().groupby(level=[0]).cumsum().reset_index()\n",
    "\n",
    "grouped_cumsum = grouped_cumsum.add_prefix('CUM_')\n",
    "\n",
    "supreme_train = pd.concat([supreme_train,grouped_cumsum['CUM_MAJOR_CHANGE_INDICATOR']],axis=1)\n",
    "\n",
    "supreme_train.rename(columns={'CUM_MAJOR_CHANGE_INDICATOR':'MAJOR_CHANGE_CNT','N':'SEMESTER_INDEX'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cumsum = supreme_dev[['EMPLID',\n",
    "                             'TERM_CODE',\n",
    "                             'EOT_ACAD_PLAN_CD',\n",
    "                             'COHORT',\n",
    "                             'MAJOR_CHANGE_INDICATOR'\n",
    "                             ]].groupby(['EMPLID',\n",
    "                                                 'TERM_CODE',\n",
    "                                                 'EOT_ACAD_PLAN_CD',\n",
    "                                                 'COHORT',\n",
    "                                                 ]).sum().groupby(level=[0]).cumsum().reset_index()\n",
    "\n",
    "grouped_cumsum = grouped_cumsum.add_prefix('CUM_')\n",
    "\n",
    "supreme_dev = pd.concat([supreme_dev,grouped_cumsum['CUM_MAJOR_CHANGE_INDICATOR']],axis=1)\n",
    "\n",
    "supreme_dev.rename(columns={'CUM_MAJOR_CHANGE_INDICATOR':'MAJOR_CHANGE_CNT','N':'SEMESTER_INDEX'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rearrange features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_var = ['COHORT', 'EMPLID']\n",
    "\n",
    "perf_var = ['TERM_CODE', 'SEMESTER_INDEX', 'EOT_ACAD_PLAN_CD', 'MAJOR_CHANGE_INDICATOR','MAJOR_CHANGE_CNT',\n",
    "            'UNITS_TAKEN','BCMP', 'A', 'AU', 'B' ,'C','CR', 'D', 'F', 'I', 'NC', 'RP', 'W', 'WE', 'WU', 'SUMMER', \n",
    "            'CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', 'TERM_GPA','CUM_GPA', 'BCMP_TERM_GPA', 'BCMP_CUM_GPA',\n",
    "            'COMPLETION_RATE', 'LOAD_INDEX_EXCLUDE', 'LOAD_INDEX_ONLY','DFW_RATE','T_COMP', 'T_READ','T_MATH']\n",
    "\n",
    "dem_var = ['GPA_HS', 'GENDR_M', 'AFRICAN AMERICAN','ASIAN AMERICAN', 'CAUCASIAN', 'LATINO/LATINA', \n",
    "           'NATIVE AMERICAN','PACIFIC ISLANDER', 'TWO OR MORE RACES, INCLUDING MINORITY',\n",
    "           'TWO OR MORE RACES, NON-MINORITIES', 'ETHNICITY UNKNOWN', 'VISA NON U.S.','CONTINUING GENERATION STUDENT', \n",
    "           'FIRST GENERATION STUDENT', 'FIRST GENERATION UNKNOWN','DEP_FAM_1', 'DEP_FAM_10', 'DEP_FAM_12', 'DEP_FAM_15', 'DEP_FAM_2',\n",
    "           'DEP_FAM_25', 'DEP_FAM_3', 'DEP_FAM_4', 'DEP_FAM_5', 'DEP_FAM_6','DEP_FAM_7', 'DEP_FAM_8', 'DEP_FAM_9', \n",
    "           'DEP_FAM_NA', 'URM_MINORITY','URM_NON-MINORITY', 'APP_FAM_1',\n",
    "           'APP_FAM_2', 'APP_FAM_3', 'APP_FAM_6', 'APP_FAM_NA','INCM_$12,000 TO $23,999', 'INCM_$6,000 TO $11,999',\n",
    "           'INCM_$60,000 OR MORE', 'INCM_LESS THEN $6000', 'PELL_NON TRADITIONAL', \n",
    "           'PELL_TRADITIONAL']\n",
    "\n",
    "resp_var = ['GRAD_IN_2.5','GRAD_IN_3.0', 'GRAD_IN_3.5', 'GRAD_IN_4.0', 'GRAD_IN_4.5','GRAD_IN_5.0', 'GRAD_IN_5.5', \n",
    "          'GRAD_IN_6.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train = supreme_train[id_var + perf_var + dem_var + resp_var]\n",
    "supreme_dev = supreme_dev[id_var + perf_var + dem_var + resp_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in supreme_train.columns: print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[['SUMMER','CUM_SUMMER','CUM_WINTER']].head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[supreme_train['EMPLID'] == '011193375']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripte Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train['GPA_HS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(supreme['TERM_CODE']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev['BCMP_TERM_GPA'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sequential Data Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up semester_index as to eliminate floats\n",
    "print(supreme_train['SEMESTER_INDEX'].unique())\n",
    "supreme_train.dropna(inplace=True)\n",
    "supreme_train['SEMESTER_INDEX'] = supreme_train['SEMESTER_INDEX'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should Dev also be cleaned up to eliminate floats?\n",
    "print(supreme_dev['SEMESTER_INDEX'].unique())\n",
    "supreme_dev['SEMESTER_INDEX'] = supreme_dev['SEMESTER_INDEX'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to numeric type\n",
    "supreme_train['TERM_CODE'] = pd.to_numeric(supreme_train['TERM_CODE'])\n",
    "supreme_dev['TERM_CODE'] = pd.to_numeric(supreme_dev['TERM_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supreme_train[supreme_train['EMPLID'] == '010841881'][['EMPLID', 'SEMESTER_INDEX', 'TERM_GPA']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = {'TRAIN0':supreme_train[id_var + dem_var + resp_var]}\n",
    "seq['DEV0'] = supreme_dev[id_var + dem_var + resp_var]\n",
    "\n",
    "seq['TRAIN0'].drop_duplicates(inplace=True)\n",
    "\n",
    "seq['DEV0'].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in supreme_train['SEMESTER_INDEX'].unique():\n",
    "    seq['TRAIN{}'.format(s)] = supreme_train[supreme_train['SEMESTER_INDEX'] <= s]\n",
    "    seq['DEV{}'.format(s)] = supreme_dev[supreme_dev['SEMESTER_INDEX'] <= s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq['TRAIN0'].shape)\n",
    "print(seq['TRAIN1'].shape)\n",
    "print(seq['TRAIN2'].shape)\n",
    "print(seq['TRAIN3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq['TRAIN0']['GRAD_IN_4.0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supreme_dev.to_csv('supreme_dev.csv')\n",
    "\n",
    "# supreme_train.to_csv('supreme_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tuner(X_train,y_train,X_dev,y_dev,model,grid = None):\n",
    "    \n",
    "    if grid == None:\n",
    "        clf = model\n",
    "    else:\n",
    "        clf = GridSearchCV(model, grid, cv=10, n_jobs = -1)\n",
    "    \n",
    "    clf_fit = clf.fit(X_train,y_train)\n",
    "    \n",
    "    if grid != None: \n",
    "        best_par = clf.best_params_\n",
    "    \n",
    "    y_dev_pred = clf.predict(X_dev)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    p_pred = clf.predict(X_dev)\n",
    "    cm = confusion_matrix(y_dev,y_dev_pred)\n",
    "    dev_accuracy = accuracy_score(y_dev,y_dev_pred)\n",
    "    train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "    report = classification_report(y_dev,y_dev_pred)\n",
    "    \n",
    "    if grid != None: \n",
    "        print ('\\nthe optimal parameters are: {}'.format(best_par))\n",
    "    \n",
    "    print ('\\naccuracy on the dev set is: {}'.format(dev_accuracy))\n",
    "    print ('\\naccuracy on the train set is: {}'.format(train_accuracy))\n",
    "    print ('\\nconfusion matrix:\\n\\n{}'.format(cm))\n",
    "    print ('\\nclassification report:\\n\\n{}'.format(report))\n",
    "    \n",
    "    if grid != None:\n",
    "        results_dict = {'best model':clf_fit,'best parameters':best_par, 'predicted dev values':y_dev_pred, \n",
    "                        'predicted training values':y_train_pred,'predicted probabilities':p_pred,\n",
    "                        'confusion matrix':cm,'dev accuracy':dev_accuracy,\n",
    "                        'training accuracy':train_accuracy,'classification report':report}\n",
    "    else:\n",
    "        results_dict = {'best model':clf_fit, 'predicted dev values':y_dev_pred, 'predicted training values':y_train_pred, \n",
    "                        'predicted probabilities':p_pred,'confusion matrix':cm,'dev accuracy':dev_accuracy,\n",
    "                        'training accuracy':train_accuracy,'classification report':report}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = [\n",
    "    \n",
    "       'MAJOR_CHANGE_CNT', 'SUMMER','TERM_GPA','BCMP_TERM_GPA','COMPLETION_RATE', 'LOAD_INDEX_EXCLUDE', \n",
    "       'LOAD_INDEX_ONLY', 'DFW_RATE', 'GPA_HS','GENDR_M', 'AFRICAN AMERICAN',\n",
    "       'ASIAN AMERICAN', 'CAUCASIAN', 'LATINO/LATINA', 'NATIVE AMERICAN', 'PACIFIC ISLANDER', \n",
    "       'TWO OR MORE RACES, INCLUDING MINORITY',\n",
    "       'TWO OR MORE RACES, NON-MINORITIES', 'ETHNICITY UNKNOWN', 'VISA NON U.S.',\n",
    "       'CONTINUING GENERATION STUDENT', 'FIRST GENERATION STUDENT', 'FIRST GENERATION UNKNOWN',\n",
    "       'DEP_FAM_1', 'DEP_FAM_10', 'DEP_FAM_12', 'DEP_FAM_15', 'DEP_FAM_2',\n",
    "       'DEP_FAM_25', 'DEP_FAM_3', 'DEP_FAM_4', 'DEP_FAM_5', 'DEP_FAM_6',\n",
    "       'DEP_FAM_7', 'DEP_FAM_8', 'DEP_FAM_9', 'DEP_FAM_NA', 'URM_MINORITY',\n",
    "       'URM_NON-MINORITY', 'APP_FAM_1',\n",
    "       'APP_FAM_2', 'APP_FAM_3', 'APP_FAM_6', 'APP_FAM_NA',\n",
    "       'INCM_$12,000 TO $23,999', 'INCM_$6,000 TO $11,999',\n",
    "       'INCM_$60,000 OR MORE', 'INCM_LESS THEN $6000', \n",
    "       'PELL_NON TRADITIONAL', 'PELL_TRADITIONAL', 'T_COMP', 'T_READ',\n",
    "       'T_MATH'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "var2 = [\n",
    "    \n",
    "       'MAJOR_CHANGE_CNT', 'A', 'AU', 'B',\n",
    "       'C', 'CR', 'D', 'F', 'I', 'NC', 'RP', 'W', 'WE', 'WU', 'SUMMER',\n",
    "       'WINTER', 'CUM_SUMMER', 'CUM_WINTER', 'CUM_GPA', 'BCMP_CUM_GPA', 'COMPLETION_RATE', \n",
    "       'LOAD_INDEX_EXCLUDE', 'LOAD_INDEX_ONLY', 'DFW_RATE', 'GPA_HS'\n",
    "    \n",
    "]\n",
    "\n",
    "var3 = [\n",
    "    \n",
    "       'MAJOR_CHANGE_CNT', 'SUMMER',\n",
    "       'WINTER', 'CUM_SUMMER', 'CUM_WINTER', 'CUM_GPA', 'BCMP_CUM_GPA', \n",
    "       'LOAD_INDEX_EXCLUDE', 'LOAD_INDEX_ONLY', 'DFW_RATE', 'GPA_HS'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "time_to_grad=4\n",
    "\n",
    "train_t = 'TRAIN{}'.format(str(t))\n",
    "dev_t = 'DEV{}'.format(str(t))\n",
    "response = 'GRAD_IN_{}.0'.format(time_to_grad)\n",
    "\n",
    "y_train = seq[train_t][response]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = seq[dev_t][['COHORT','EMPLID',response]]\n",
    "y_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = seq[train_t][dem_var]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = seq[dev_t][dem_var]\n",
    "X_train, y_train = SMOTE().fit_sample(X_train, y_train)\n",
    "#X_dev, y_dev = SMOTE().fit_sample(X_dev, y_dev)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=X_train,columns=train_col).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data(t, time_to_grad, features):\n",
    "    train_t = 'TRAIN{}'.format(str(t))\n",
    "    dev_t = 'DEV{}'.format(str(t))\n",
    "    response = 'GRAD_IN_{}.0'.format(time_to_grad)\n",
    "\n",
    "    y_train = seq[train_t][response]\n",
    "    y_dev = seq[dev_t][response]\n",
    "    X_train = seq[train_t][features]\n",
    "    X_dev = seq[dev_t][features]\n",
    "\n",
    "    X_train, y_train = SMOTE().fit_sample(X_train, y_train)\n",
    "    X_train = pd.DataFrame(data=X_train,columns=features)\n",
    "    #X_dev, y_dev = SMOTE().fit_sample(X_dev, y_dev)\n",
    "    \n",
    "    return (X_train,y_train,X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_matrix_fn(df, data):\n",
    "    aMat = df\n",
    "    aMat = aMat.append(pd.DataFrame(data), sort=False)\n",
    "    aMat.reset_index(inplace=True,drop=True)\n",
    "    return aMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model,grid = None,label=None):\n",
    "    n_features = len(X_train.columns)\n",
    "    n_obs = len(y_train)\n",
    "    start = time.time()\n",
    "    results_log = model_tuner(X_train,y_train,X_dev,y_dev,model,grid)\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    print ('the runtime is {} minutes'.format(runtime/60))\n",
    "    \n",
    "    return {'model':label, 'Number of Features': n_features, 'Number of Obs': n_obs, 'dev accuracy':[results_log['dev accuracy']], 'training accuracy':[results_log['training accuracy']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def lasso_reduction(X_train, X_dev):\n",
    "#     clf = LassoCV(cv=10, random_state=random_state)\n",
    "#     clf.fit(X_train,y_train)\n",
    "#     alpha = clf.alpha_\n",
    "#     coef = clf.coef_\n",
    "#     sfm = SelectFromModel(clf)\n",
    "#     sfm.fit(X_train,y_train)\n",
    "#     selection = sfm.get_support()\n",
    "#     X_train = pd.DataFrame(sfm.transform(X_train), columns=X_dev.columns[selection])\n",
    "#     X_dev = pd.DataFrame(X_dev.iloc[:,selection])\n",
    "#     return X_train, X_dev, alpha, coef, selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train,X_dev,y_dev = seq_data(t=1, time_to_grad=4, features=var)\n",
    "# X_train, X_dev, alpha, coef, selection = lasso_reduction(X_train, X_dev)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic at $t_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=0, time_to_grad=4, features=dem_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mod = LogisticRegression(solver='lbfgs', max_iter=10000, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_log_accuracy = run_model(model=log_mod,label='logistic @ t0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix = pd.DataFrame()\n",
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t0_log_accuracy), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic at $t_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=1, time_to_grad=4, features=var)\n",
    "\n",
    "t1_log_accuracy = run_model(model=log_mod,label='logistic @ t1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t1_log_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic at $t_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=2, time_to_grad=4, features=var)\n",
    "t2_log_accuracy = run_model(model=log_mod,label='logistic @ t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t2_log_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic at $t_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=3, time_to_grad=4, features=var)\n",
    "t3_log_accuracy = run_model(model=log_mod,label='logistic @ t3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t3_log_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic at $t_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=4, time_to_grad=4, features=var)\n",
    "t4_log_accuracy = run_model(model=log_mod,label='logistic @ t4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t4_log_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "accuracy_matrix.plot(kind='line',x='model',y='dev accuracy',ax=ax)\n",
    "accuracy_matrix.plot(kind='line',x='model',y='training accuracy', color='red', ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest @ $t_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train,X_dev,y_dev = seq_data(t=0, time_to_grad=4, features=dem_var)\n",
    "# X_train, X_dev, alpha, coef, selection = lasso_reduction(X_train, X_dev)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=0, time_to_grad=4, features=dem_var)\n",
    "\n",
    "\n",
    "parameters_rf = {'n_estimators':[100,100],'max_features':[1,int(np.sqrt(len(dem_var)))],'max_depth':[10,10]}\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state = random_state)\n",
    "\n",
    "t0_rf_accuracy = run_model(model=rf,grid=parameters_rf,label='random forest @ t0')\n",
    "\n",
    "accuracy_matrix = pd.DataFrame()\n",
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t0_rf_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest @ $t_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_var  = ['COHORT', 'EMPLID', 'TERM_CODE', 'SEMESTER_INDEX','MAJOR_CHANGE_INDICATOR', 'MAJOR_CHANGE_CNT', 'UNITS_TAKEN', 'BCMP',\n",
    "#        'A', 'AU', 'B', 'C', 'CR', 'D', 'F', 'I', 'NC', 'RP', 'W', 'WE', 'WU',\n",
    "#        'SUMMER', 'CUM_BCMP', 'CUM_SUMMER', 'CUM_WINTER', 'TERM_GPA', 'CUM_GPA',\n",
    "#        'BCMP_TERM_GPA', 'BCMP_CUM_GPA', 'COMPLETION_RATE',\n",
    "#        'LOAD_INDEX_EXCLUDE', 'LOAD_INDEX_ONLY', 'DFW_RATE', 'T_COMP', 'T_READ',\n",
    "#        'T_MATH', 'GPA_HS', 'GENDR_M', 'AFRICAN AMERICAN', 'ASIAN AMERICAN',\n",
    "#        'CAUCASIAN', 'LATINO/LATINA', 'NATIVE AMERICAN', 'PACIFIC ISLANDER',\n",
    "#        'TWO OR MORE RACES, INCLUDING MINORITY',\n",
    "#        'TWO OR MORE RACES, NON-MINORITIES', 'ETHNICITY UNKNOWN',\n",
    "#        'VISA NON U.S.', 'CONTINUING GENERATION STUDENT',\n",
    "#        'FIRST GENERATION STUDENT', 'FIRST GENERATION UNKNOWN', 'DEP_FAM_1',\n",
    "#        'DEP_FAM_10', 'DEP_FAM_12', 'DEP_FAM_15', 'DEP_FAM_2', 'DEP_FAM_25',\n",
    "#        'DEP_FAM_3', 'DEP_FAM_4', 'DEP_FAM_5', 'DEP_FAM_6', 'DEP_FAM_7',\n",
    "#        'DEP_FAM_8', 'DEP_FAM_9', 'DEP_FAM_NA', 'URM_MINORITY',\n",
    "#        'URM_NON-MINORITY', 'APP_FAM_1', 'APP_FAM_2', 'APP_FAM_3', 'APP_FAM_6',\n",
    "#        'APP_FAM_NA', 'INCM_$12,000 TO $23,999', 'INCM_$6,000 TO $11,999',\n",
    "#        'INCM_$60,000 OR MORE', 'INCM_LESS THEN $6000', 'PELL_NON TRADITIONAL',\n",
    "#        'PELL_TRADITIONAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train,X_dev,y_dev = seq_data(t=1, time_to_grad=4, features=var)\n",
    "# X_train, X_dev, alpha, coef, selection = lasso_reduction(X_train, X_dev)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=1, time_to_grad=4, features=var)\n",
    "\n",
    "parameters_rf = {'n_estimators':[100,100],'max_features':[1,int(np.sqrt(len(var)))],'max_depth':[1,32]}\n",
    "\n",
    "t1_rf_accuracy = run_model(model=rf,grid=parameters_rf, label='random forest @ t1')\n",
    "\n",
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t1_rf_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest @ $t_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=2, time_to_grad=4, features=var)\n",
    "\n",
    "t2_rf_accuracy = run_model(model=rf,grid=parameters_rf, label='random forest @ t2')\n",
    "\n",
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t2_rf_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest @ $t_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=3, time_to_grad=4, features=var)\n",
    "\n",
    "t3_rf_accuracy = run_model(model=rf,grid=parameters_rf, label='random forest @ t3')\n",
    "\n",
    "accuracy_matrix = accuracy_matrix.append(pd.DataFrame(t3_rf_accuracy), sort=False)\n",
    "accuracy_matrix.reset_index(inplace=True,drop=True)\n",
    "accuracy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.gca()\n",
    "\n",
    "# accuracy_matrix.plot(kind='line',x='model',y='dev accuracy',ax=ax)\n",
    "# accuracy_matrix.plot(kind='line',x='model',y='training accuracy', color='red', ax=ax)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=3, time_to_grad=4, features=rf_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost @ $t_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_xgb(label,num_round):\n",
    "    \n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_dev = xgb.DMatrix(X_dev, label=y_dev)\n",
    "    \n",
    "    param = {'max_depth': 6, 'eta': 0.6, 'objective': 'binary:logistic'}\n",
    "    param['nthread'] = 4\n",
    "    param['eval_metric'] = 'auc'\n",
    "    evallist = [(d_dev, 'eval'), (d_train, 'train')]\n",
    "\n",
    "    bst = xgb.train(param, d_train, num_round, evallist, verbose_eval=True)\n",
    "    \n",
    "    y_dev_pred = (bst.predict(d_dev) > 0.5) * 1\n",
    "    y_train_pred = (bst.predict(d_train) > 0.5) * 1\n",
    "    p_pred = bst.predict(d_dev)\n",
    "    cm = confusion_matrix(y_dev,y_dev_pred)\n",
    "    dev_accuracy = accuracy_score(y_dev,y_dev_pred)\n",
    "    train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "    dev_f1 = f1_score(y_dev,y_dev_pred)\n",
    "    train_f1 = f1_score(y_train,y_train_pred)\n",
    "    dev_precision = precision_score(y_dev,y_dev_pred)\n",
    "    train_precision = precision_score(y_train,y_train_pred)\n",
    "    dev_recall = recall_score(y_dev,y_dev_pred)\n",
    "    train_recall = recall_score(y_train,y_train_pred)\n",
    "    dev_roc = roc_auc_score(y_dev,y_dev_pred)\n",
    "    train_roc = roc_auc_score(y_train,y_train_pred)\n",
    "    report = classification_report(y_dev,y_dev_pred)\n",
    "    \n",
    "    print ('\\naccuracy on the dev set is: {}'.format(dev_accuracy))\n",
    "    print ('\\naccuracy on the train set is: {}'.format(train_accuracy))\n",
    "    print ('\\nconfusion matrix:\\n\\n {}'.format(cm))\n",
    "    print ('\\nclassification report:\\n\\n{}'.format(report))\n",
    "    \n",
    "    metrics = {'model':label,\n",
    "               'dev accuracy':[dev_accuracy], \n",
    "               'training accuracy':[train_accuracy],\n",
    "               'dev f1':[dev_f1],\n",
    "               'training f1':[train_f1],\n",
    "               'dev precision':[dev_precision],\n",
    "               'training precision':[train_precision],\n",
    "               'dev recall':[dev_recall],\n",
    "               'training recall':[train_recall],\n",
    "               'dev roc':[dev_roc],\n",
    "               'training roc':[train_roc]\n",
    "              } \n",
    "    \n",
    "    predict = {'predicted dev values':[y_dev_pred],\n",
    "               'predicted training values':[y_train_pred],\n",
    "               'predicted probabilities':[p_pred],\n",
    "               'confusion matrix':[cm],\n",
    "               'classification report':[report]}\n",
    "    \n",
    "    return (metrics, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=0, time_to_grad=4, features=dem_var)\n",
    "metrics,_ = run_model_xgb('xgb@t0',epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mat = accuracy_matrix_fn(pd.DataFrame(), metrics)\n",
    "acc_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost @ $t_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=1, time_to_grad=4, features=var)\n",
    "\n",
    "metrics,_ = run_model_xgb('xgb@t1',epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-y_dev.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mat = accuracy_matrix_fn(acc_mat,metrics)\n",
    "acc_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost @ $t_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=2, time_to_grad=4, features=var)\n",
    "metrics,_ = run_model_xgb('xgb@t2',epochs)\n",
    "\n",
    "acc_mat = accuracy_matrix_fn(acc_mat,metrics)\n",
    "acc_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost @ $t_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=3, time_to_grad=4, features=var)\n",
    "metrics,_ = run_model_xgb('xgb@t3',epochs)\n",
    "\n",
    "acc_mat = accuracy_matrix_fn(acc_mat,metrics)\n",
    "acc_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost @ $t_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_dev,y_dev = seq_data(t=4, time_to_grad=4, features=var)\n",
    "metrics,_ = run_model_xgb('xgb@t4',epochs)\n",
    "\n",
    "acc_mat = accuracy_matrix_fn(acc_mat,metrics)\n",
    "acc_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq['TRAIN2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
